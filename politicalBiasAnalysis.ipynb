{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "all_tweets = pd.read_csv(f\"tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets.columns = all_tweets.columns.str.strip()\n",
    "all_categories = all_tweets.political_inclination.unique()\n",
    "all_categories.sort()\n",
    "print(list(all_categories))\n",
    "all_tweets.head()\n",
    "all_tweets.describe()\n",
    "all_tweets.groupby('political_inclination').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove links\n",
    "import re\n",
    "\n",
    "all_tweets.text = all_tweets.text.apply(lambda x: re.sub(\n",
    "    r'RT @[a-zA-Z0-9_]+:|@[a-zA-Z0-9_]+|http\\S+', '', x))\n",
    "print(all_tweets.text.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = all_tweets.political_inclination\n",
    "x = all_tweets.drop(\"political_inclination\", axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=23, stratify=y)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "stemmer = EnglishStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "stem_vectorizer = CountVectorizer(analyzer=stemmed_words, lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# {'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__analyzer': < function stemmed_words at 0x12fbda550 >, 'vect__stop_words': None}\n",
    "nb_pipeline = Pipeline(\n",
    "    [\n",
    "        ('vect', stem_vectorizer),\n",
    "        ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "        ('clf', MultinomialNB(alpha=0.01))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_nb = nb_pipeline.fit(x_train.text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf_nb.predict(x_test.text)\n",
    "\n",
    "print(classification_report(y_test, predicted))\n",
    "print(accuracy_score(y_test, predicted))\n",
    "\n",
    "matrix = confusion_matrix(y_test, predicted,labels=list(all_categories))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'clf-svm__alpha': 0.001, 'clf-svm__loss': 'modified_huber', 'clf-svm__penalty': 'l2', 'tfidf__use_idf': True}\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf_svm = Pipeline(\n",
    "    [\n",
    "        ('vect', stem_vectorizer),\n",
    "        ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "        ('clf-svm', SGDClassifier(alpha=0.001, loss='modified_huber', penalty='l2'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "_ = text_clf_svm.fit(x_train.text, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svm = text_clf_svm.predict(x_test.text)\n",
    "\n",
    "print(classification_report(y_test, predicted_svm))\n",
    "print(accuracy_score(y_test, predicted_svm))\n",
    "\n",
    "matrix = confusion_matrix(y_test, predicted_svm,labels=list(all_categories))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "text_clf_rf = Pipeline(\n",
    "    [\n",
    "        ('vect', stem_vectorizer),\n",
    "        ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "        ('clf-rf', RandomForestClassifier(n_estimators=100))\n",
    "    ]\n",
    ")\n",
    "\n",
    "_ = text_clf_rf.fit(x_train.text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rf = text_clf_rf.predict(x_test.text)\n",
    "\n",
    "print(classification_report(y_test, predicted_rf))\n",
    "print(accuracy_score(y_test, predicted_rf))\n",
    "\n",
    "matrix = confusion_matrix(y_test, predicted_rf, labels=list(all_categories))\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "text_clf_knn = Pipeline(\n",
    "    [\n",
    "        ('vect', stem_vectorizer),\n",
    "        ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "        ('clf-knn', KNeighborsClassifier(n_neighbors=7))\n",
    "    ]\n",
    ")\n",
    "\n",
    "_ = text_clf_knn.fit(x_train.text, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_knn = text_clf_knn.predict(x_test.text)\n",
    "\n",
    "print(confusion_matrix(y_test, predicted_knn))\n",
    "print(classification_report(y_test, predicted_knn))\n",
    "print(accuracy_score(y_test, predicted_knn))\n",
    "\n",
    "matrix = confusion_matrix(y_test, predicted_knn, labels=list(all_categories))\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "text_clf_mlp = Pipeline(\n",
    "    [\n",
    "        ('vect', stem_vectorizer),\n",
    "        ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "        ('clf-mlp', MLPClassifier(\n",
    "            solver='lbfgs', \n",
    "            alpha=1e-5, \n",
    "            hidden_layer_sizes=(25, 11, 7, 5, 3,),\n",
    "            random_state=1,\n",
    "            max_iter=30000\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "_ = text_clf_mlp.fit(x_train.text, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mlp = text_clf_mlp.predict(x_test.text)\n",
    "\n",
    "print(confusion_matrix(y_test, predicted_mlp))\n",
    "print(classification_report(y_test, predicted_mlp))\n",
    "print(accuracy_score(y_test, predicted_mlp))\n",
    "\n",
    "matrix = confusion_matrix(y_test, predicted_mlp, labels=list(all_categories))\n",
    "print(matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID Search (Very time consuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV as GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "parameters_mlp = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf-mlp__lbfgs': ('lbfgs', 'sgd', 'adam'),\n",
    "    'clf-mlp__alpha': (1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001),\n",
    "    'clf-mlp__hidden_layer_sizes': ((15,), (5, 2), (5, 3), (5, 4), (5, 5), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (5, 15), (5, 16), (5, 17), (5, 18), (5, 19), (5, 20), (5, 21), (5, 22), (5, 23), (5, 24), (5, 25), (5, 26), (5, 27), (5, 28), (5, 29), (5, 30), (5, 31), (5, 32), (5, 33), (5, 34), (5, 35), (5, 36), (5, 37), (5, 38), (5, 39), (5, 40), (5, 41), (5, 42), (5, 43), (5, 44), (5, 45), (5, 46), (5, 47), (5, 48), (5, 49), (5, 50), (5, 51), (5, 52), (5, 53), (5, 54), (5, 55), (5, 56), (5, 57), (5, 58), (5, 59), (5, 60), (5, 61), (5, 62), (5, 63), (5, 64), (5, 65), (5, 66), (5, 67), (5, 68), (5, 69), (5, 70), (5, 71), (5, 72), (5, 73), (5, 74), (5, 75), (5, 76), (5, 77), (5, 78), (5, 79), (5, 80), (5, 81), (5, 82), (5, 83), (5, 84), (5, 85), (5, 86), (5, 87), (5, 88), (5, 89), (5, 90), (5, 91), (5, 92), (5, 93), (5, 94), (5, 95), (5, 96), (5, 97), (5, 98), (5, 99), (5, 100), (5, 101), (25, 11, 7, 5, 3,), (25, 11, 7, 5, 3,))\n",
    "}\n",
    "\n",
    "gs_clf_knn = GridSearchCV(text_clf_mlp, parameters_mlp, n_jobs=-1, verbose=1)\n",
    "gs_clf_knn = gs_clf_knn.fit(x_train.text, y_train)\n",
    "print(gs_clf_knn.best_score_)\n",
    "print(gs_clf_knn.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__analyzer': [stemmed_words, \"word\"],\n",
    "    'vect__stop_words': [None, \"english\"],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf_nb, parameters, n_jobs=-1, verbose=1)\n",
    "gs_clf = gs_clf.fit(x_train.text, y_train)\n",
    "\n",
    "print(gs_clf.best_score_)\n",
    "print(gs_clf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf-svm__alpha': (1e-2, 1e-3),\n",
    "    'clf-svm__loss': (\"hinge\", \"log_loss\", \"modified_huber\", \"squared_hinge\", \"squared_error\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"),\n",
    "    'clf-svm__penalty': (\"l2\", \"l1\", \"elasticnet\")\n",
    "}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1, verbose=1)\n",
    "gs_clf_svm = gs_clf_svm.fit(x_train.text, y_train)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_knn = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf-knn__n_neighbors': (3, 5, 7, 9, 11, 13, 15),\n",
    "}\n",
    "gs_clf_knn = GridSearchCV(text_clf_knn, parameters_knn, n_jobs=-1, verbose=1)\n",
    "gs_clf_knn = gs_clf_knn.fit(x_train.text, y_train)\n",
    "print(gs_clf_knn.best_score_)\n",
    "print(gs_clf_knn.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rf = {\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf-rf__alpha': (1e-2, 1e-3),\n",
    "    'clf-rf__penalty': (\"l2\", \"l1\", \"elasticnet\"),\n",
    "    'clf-rf__bootstrap': [True, False],\n",
    "    'clf-rf__max_depth': [10, 20, 30, None],\n",
    "}\n",
    "gs_clf_rf = GridSearchCV(text_clf_rf, parameters_rf, n_jobs=-1, verbose=1)\n",
    "gs_clf_rf = gs_clf_rf.fit(x_train.text, y_train)\n",
    "print(gs_clf_rf.best_score_)\n",
    "print(gs_clf_rf.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
